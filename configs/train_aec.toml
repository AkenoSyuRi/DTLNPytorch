[meta]
seed = 42 # random seed
use_amp = false # use automatic mixed precision, it will benefits Tensor Core-enabled GPU (e.g. Volta, Turing, Ampere). 2-3X speedup
num_workers = 4
pin_memory = true 
num_epochs = 200
batch_size = 16
clean_list_path = "/home/lizhinan/project/lightse/DTLNPytorch/dataset/clean_dataset_list_aec.txt"
mic_list_path = "/home/lizhinan/project/lightse/DTLNPytorch/dataset/mic_dataset_list_aec.txt"
ref_list_path = "/home/lizhinan/project/lightse/DTLNPytorch/dataset/ref_dataset_list_aec.txt"
noise_list_path = "/home/lizhinan/project/lightse/DTLNPytorch/dataset/noiselist0321.txt"
# set experiment dir.
save_model_dir = "/home/lizhinan/project/lightse/DTLNPytorch/models"
experiment_name = "DTLN-aec Trainfinetune_singletalk 0327_stateful"
# set preload model
preload_model_path = "/home/lizhinan/project/lightse/DTLNPytorch/models/DTLN-aec TrainTest 0324_stateful/checkpoints/model_0118.pth"




[audio]
samplerate = 48000
duration = 13


[model]
#path = "modules.dtlnModel_Stateful.DTLN_modelForNS_Stateful"
path = "modules.dtlnModel_aec_Stateful.DTLN_modelForAec_Stateful"
stateful = true
[model.args]
frameLength = 2048
hopLength = 512
# seperation kernel config
hiddenSizeOfRNN = 512
typeOfRNN = 'LSTM'
#numOfRNNLayers = 2
# Conv1d config
numOfConv_Features = 256

[optimizer]
lr = 0.001
weight_decay = 2e-7

[trainer]
path = "modules.trainer.Trainer"
[trainer.args]
clip_grad_norm_ornot = true
clip_grad_norm_value = 2